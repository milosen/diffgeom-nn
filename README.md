# Understanding "Principles of Riemannian Geometry in Neural Networks" by Michael Hauser and Asok Ray

## Topics to look into
* geomstat + pytorch?
* understanding dimensionality reduction
    - locally linear embedding
    - why euclidean metric in output space
* lie group actions on fibre bundles
* submersion / immersion of manifolds
* connection (principal bundle)
* residual neural networks recap

## Resources on differential geometry and lie groups
* nice intro to lie groups and lie algebras: https://www.liealgebrasintro.com/publications
* great theoretical physics blog: http://jakobschwichtenberg.com/

## Cited By

* Residual Networks as Flows of Diffeomorphisms (Rousseau, F., Drumetz, L., Fablet, R. 2020 Journal of Mathematical Imaging and Vision)

* State-space representations of deep neural networks (Hauser, M., Gunn, S., Saab, S., Ray, A. 2019 Neural Computation)

* Demystifying deep learning: A geometric approach to iterative projections (Panahi, A., Krim, H., Dai, L. 2018 ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings)

* Model-based vs data-driven adaptive control: An overview (Benosman, M. 2018 International Journal of Adaptive Control and Signal Processing)
